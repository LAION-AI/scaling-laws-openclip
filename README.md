# Reproducible scaling laws for contrastive language-image learning [[arXiv]](https://arxiv.org/abs/)

Work still in progress. In this repository, we will provide the code for reproducing the experiments on large-scale CLIP pre-training and transfer to various downstream tasks for the paper "Reproducible scaling laws for contrastive language-image learning".

Stay tuned.

Until finalized, you may check

- the openCLIP repository that points to pre-trained models used in this study: https://github.com/mlfoundations/open_clip
- the [LAION-400m](https://github.com/rom1504/img2dataset/blob/main/dataset_examples/laion400m.md) and [LAION-5B](https://github.com/rom1504/img2dataset/blob/main/dataset_examples/laion5B.md) composition instructions, the datasets used for openCLIP pre-training in this study
- [CLIP Benchmarking](https://github.com/LAION-AI/CLIP_benchmark), transfer evaluation used in this study

## Introduction

## Organization

## Installation

## Citation

If you find this work helpful, please cite our paper:

```
@article{,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={},
  journal={},
  year={2022}
}
```
## Acknowledgements
